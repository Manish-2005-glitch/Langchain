{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c66202e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e17f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8798e09",
   "metadata": {},
   "source": [
    "Indexing (Document Ingestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a5e13",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67ea584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api._api import YouTubeTranscriptApi\n",
    "\n",
    "video_id = \"Gfr50f6ZBvo\"\n",
    "\n",
    "try:\n",
    "    api = YouTubeTranscriptApi()\n",
    "    transcript_list = api.fetch(video_id)\n",
    "    \n",
    "    transcript = \" \".join([snippet.text for snippet in transcript_list])\n",
    " \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f129fd2",
   "metadata": {},
   "source": [
    "Indexing(Text Splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af11b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "chunks = splitter.create_documents([transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71790485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84adb43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23c46a747bf47d0a4bd6b6c0294832c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f3e351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02c0fc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'da612907-323d-449d-ae69-3a34e8c0628c',\n",
       " 1: '0dab45f4-3be0-4c97-81fe-b4e832fb25fe',\n",
       " 2: 'b860cf04-9eaf-4d9c-9849-f2435a53bea9',\n",
       " 3: '3f01f7a3-a62d-4103-8f9e-4119c4819ef5',\n",
       " 4: '5652da18-e0d4-4f94-8cfd-544f70abfd4a',\n",
       " 5: '296c103a-c162-4f4a-abb5-c0ab0e7a3782',\n",
       " 6: '0c968529-3e3b-4aae-a5b1-2687ca40b138',\n",
       " 7: '7d2c7d41-8f28-4f50-9454-5b8f3263700f',\n",
       " 8: 'cfc8c49e-f805-4c6a-bc24-403d997d2442',\n",
       " 9: '39e9c2f7-8df8-49ac-bed2-df0af5259380',\n",
       " 10: '08d17d68-c361-41f3-a26f-df4c354d7a73',\n",
       " 11: 'f6252049-9806-4d70-9287-fbd91d91e8c9',\n",
       " 12: '51bca99f-71cd-46ee-9f27-ec1f6be42ca4',\n",
       " 13: 'c24e1d45-927c-4104-8bf0-25811a066b0e',\n",
       " 14: '8dac42a1-2bba-4be6-8262-9e91b48bb52c',\n",
       " 15: '58ac7c73-4111-48b5-965b-2edc07d87e31',\n",
       " 16: 'bde942aa-ceb1-4703-97f8-4fd9da991b5e',\n",
       " 17: '9a07b823-eab1-410d-ba8f-317a6e872749',\n",
       " 18: '36e08cf2-48c2-43cd-8454-126100a0f0f8',\n",
       " 19: 'd41b84ae-b562-493f-a214-0e31e88403a6',\n",
       " 20: '73790564-f47c-4202-a13b-fd6ae1511e51',\n",
       " 21: 'e9633c07-e82e-4d15-8236-8b862fb51da9',\n",
       " 22: 'f6b8b1bb-0fa1-41f2-9c00-9fcf9b7f770a',\n",
       " 23: '359503b9-4e36-46bc-9076-6623023533b0',\n",
       " 24: '17f9876c-e492-421f-8792-59f2f2ecc3b3',\n",
       " 25: 'ccc50ef6-e041-4f6a-aa00-0f67160a6cff',\n",
       " 26: '9761fb3d-89e6-462b-8e63-6025aebea154',\n",
       " 27: '3dc9df3f-e8bb-4225-84df-e92b94cef1a8',\n",
       " 28: '7191332a-8f32-49ea-8c0e-84d04a7c5780',\n",
       " 29: '61fe24e9-cc71-47eb-b891-3767d4b7a68c',\n",
       " 30: '4b601b71-9184-4714-b166-8d0b76eaa86d',\n",
       " 31: 'a9ca8ef0-d415-4d82-92e0-c2e3a11400f5',\n",
       " 32: 'b96bf793-f439-4a7d-80dc-bc9801d31ae8',\n",
       " 33: '1f523ada-a835-41a5-9cc6-d20d19a8ef32',\n",
       " 34: '93440600-1aad-45c4-bbce-8c1171d6dddd',\n",
       " 35: 'c53c2bc4-cf3e-4811-bbdf-3c8e48900845',\n",
       " 36: '0b103bb1-c785-4ca2-9c10-f6b0dc3b0558',\n",
       " 37: '7d099df3-bb11-42f1-b6b6-4417876a37a1',\n",
       " 38: '49edfdbc-c840-466e-909a-6e27021c6ad9',\n",
       " 39: '44c4668b-1392-4855-bd2c-42b5689ade9e',\n",
       " 40: 'b089ecbe-694e-43d4-8884-35463a844ae9',\n",
       " 41: 'e6959372-8faf-431b-918b-a1b08fc69428',\n",
       " 42: 'd3860f28-78b5-4078-95a6-7831f88d2a79',\n",
       " 43: '47f3985f-f24e-4676-91f5-c9ae20c0bd25',\n",
       " 44: 'f5d2b026-1892-4d1a-87a6-41f0cff35453',\n",
       " 45: '459e2aad-157e-4dd5-a780-c413b0c17e6f',\n",
       " 46: '00b1c929-5b7f-442b-9ea7-82c161d68402',\n",
       " 47: 'f4024c75-d811-4f46-9e1b-fd458a25a776',\n",
       " 48: '784a510e-368a-4584-a68c-10a6b8b63b81',\n",
       " 49: 'c0a033c1-8f56-4113-be3f-9c9be461ac75',\n",
       " 50: '972183ba-ee6d-479a-9445-724829b8eb46',\n",
       " 51: '3307622a-e9aa-4093-b8f6-80b9ef763bba',\n",
       " 52: '56420676-6908-4446-90db-2e612ba1bb91',\n",
       " 53: 'e9faf946-951c-4a4f-bedc-bd0d12ee3943',\n",
       " 54: '26bd2ccb-86c8-4bf4-9d63-a7fa0cd87aa3',\n",
       " 55: '7127aa46-9445-4f39-b3c5-be189aec2abd',\n",
       " 56: '7b17af73-9919-4514-aedd-0988cc14027f',\n",
       " 57: '536a7bc5-3546-49aa-afc9-7d41e94fdd23',\n",
       " 58: 'c094dc91-9a78-4d88-a0aa-8da5264a1d81',\n",
       " 59: '6c7971b3-e11d-4e21-8136-058e37ae9144',\n",
       " 60: '1a67f3da-f252-4918-9386-823ab2d6a948',\n",
       " 61: 'cdc61a17-0b45-4d28-870b-a47db5ec087f',\n",
       " 62: 'a72a5117-15ce-42ee-bd06-da9f851796ad',\n",
       " 63: 'cadfc2c6-2dde-4587-a5b0-3a488ff344dc',\n",
       " 64: '05179042-6cdf-4687-b824-74d3ff88e3e3',\n",
       " 65: '7de9459f-95cd-457b-b32e-263fc32583c7',\n",
       " 66: 'ad480579-e35f-4f14-b0e6-abb1dff1a5b7',\n",
       " 67: '2947b3ad-7346-4b56-bbba-cb594bdf30f5',\n",
       " 68: 'ad9153a3-77e0-4c50-9212-9d0603491e22',\n",
       " 69: 'a9fc2091-555c-4e75-b870-7b99519ca56b',\n",
       " 70: '74ddeae0-aee0-4bcb-95b0-f6c8ec62e228',\n",
       " 71: '79032ead-4925-438a-b61b-268e325bcfa9',\n",
       " 72: 'a78c9393-e5bb-43c4-80b0-0c9286aa8326',\n",
       " 73: 'a5b515a8-371a-4dd0-a7b5-19d0f7e71d31',\n",
       " 74: 'd73058d2-3c24-43dd-a1ae-e6d24f7b331c',\n",
       " 75: '48a92640-65bd-4fa4-8ba7-a33de51dd5c7',\n",
       " 76: '7ab450b5-70bc-4397-981f-7fde1c5a4828',\n",
       " 77: '79727fd8-98ac-433c-83db-45d3a8728c2c',\n",
       " 78: 'e1b8a00d-7a66-4134-a2ec-fd2b9c2ebcb3',\n",
       " 79: '45022700-e27f-475d-8206-47065cff774a',\n",
       " 80: '05e9e2d4-8a7c-4ec5-8560-bf85a622883e',\n",
       " 81: '9b3fd399-3812-46a5-ad36-50af92e9a370',\n",
       " 82: '749ea859-9ffe-4c63-ad8c-65a2ff96a94b',\n",
       " 83: 'cd7cdff3-b000-4ea2-b0a1-d87e56253fa0',\n",
       " 84: 'ecce3026-8d52-4328-a02a-5bbf64fd8c5b',\n",
       " 85: '9e1d587e-7e80-4de7-94a8-d516ee33c026',\n",
       " 86: '2d2fe337-49e5-4ce0-8dee-bf03f592250f',\n",
       " 87: 'c9366ef2-1e79-41a2-9ef4-6d251eb86f10',\n",
       " 88: 'e94dd091-cee9-43f9-800c-a8c4dd47afb9',\n",
       " 89: '6e41236e-5d80-4ece-bec5-3973f5703c03',\n",
       " 90: '4f68f66e-44e3-4c32-91be-d7d94352e79d',\n",
       " 91: '6d7a567d-b1ca-486f-977d-077926054635',\n",
       " 92: '2cca531c-cefd-4122-9e7b-873f5a36e843',\n",
       " 93: 'c8b9ed43-7d9a-49de-afd1-b8a8cebe575a',\n",
       " 94: 'a1ba2354-c076-45fa-867c-fa45689e3ba6',\n",
       " 95: 'd3345c1b-8da4-4fd6-84d0-dce204007ff5',\n",
       " 96: '613f0794-20ee-4004-b856-11b1a6477e9d',\n",
       " 97: '1957cb52-64c7-4864-8f60-ab94a4d91976',\n",
       " 98: '89bc4a52-1b0c-4c1b-9585-9fcd1835a3b1',\n",
       " 99: 'ac12cd80-5941-4131-bcd0-028cebbae96d',\n",
       " 100: '279ad502-4337-4674-96c6-3ddfe525f896',\n",
       " 101: 'd5e4072a-1ec2-423e-9c97-7f12ca1eb890',\n",
       " 102: '39fff1e3-256b-40ae-8f59-34052881ef1f',\n",
       " 103: 'f402f6c5-6c26-49f1-a567-afa3cd19029f',\n",
       " 104: '012963d1-973b-48a6-9d5e-813134109999',\n",
       " 105: 'd6a9eecb-ed92-4bd3-add9-004c1d38f745',\n",
       " 106: '70bf6d4b-7800-4697-9fad-c6acf5fdd8ec',\n",
       " 107: 'a290bf23-f2b2-4c70-a5a0-966a006b7cee',\n",
       " 108: 'b14ac55d-33f9-4b86-8f5b-a4a95f37d9a8',\n",
       " 109: '75604b7c-8abf-40b6-b7b4-f90508bfaf52',\n",
       " 110: '53219e2d-4172-4648-acfb-212f06372397',\n",
       " 111: '71493f90-50c5-4bc6-a0ba-5f8efac4e16c',\n",
       " 112: 'aad7138b-f629-4774-9a2d-01ec2be635d7',\n",
       " 113: '7788b081-8a3a-42b4-852f-b931082137cd',\n",
       " 114: 'ee689e0a-dbcc-4d82-b090-fecfd222329b',\n",
       " 115: '5de82de3-8742-4ed0-8ffd-fc9d6d72b7e7',\n",
       " 116: '861fba44-3022-4d1b-b8f8-fcf9e6104efb',\n",
       " 117: '9e80db38-4b9a-4b7a-9458-369784c3ea7b',\n",
       " 118: 'b456e50b-4908-4835-aaa7-5be64766cac8',\n",
       " 119: 'a6759c6a-098c-40c4-937d-7506cea7a392',\n",
       " 120: '01cef592-f50d-4cf2-9f45-cf83f218b325',\n",
       " 121: '81a22867-c83f-40e6-9351-755e25273f8e',\n",
       " 122: '910584e7-2f04-4826-907e-79ae928de2ae',\n",
       " 123: 'befa62f9-2925-4cf7-b9fb-ca6f069af054',\n",
       " 124: '250baf8e-5320-45a1-8fea-4f15a03e2e2f',\n",
       " 125: 'b56df413-8baf-432c-8a99-4e2845b9bcab',\n",
       " 126: '356961c7-4d6f-4513-9186-38c7d66f6e60',\n",
       " 127: '7dd05274-37e8-4079-bab2-002ad28e33a9',\n",
       " 128: 'dbd40d41-6f21-4bf4-b469-9f148890b9c5',\n",
       " 129: 'ff1fd0a6-0581-4a77-b25e-b9a69d1035e8',\n",
       " 130: '2b550f38-197e-48d8-bf6a-62b0d8a6913d',\n",
       " 131: 'b14ebb04-56c7-4600-9f93-de75857ca354',\n",
       " 132: '54a46c0e-29a1-4c8a-b090-94d4262fce61',\n",
       " 133: '876dc1fd-0c94-42a5-baf5-dd0c9f11e541',\n",
       " 134: 'b19b3ba9-ba2e-44c8-8842-e152f76f9d93',\n",
       " 135: '9e66f970-d498-4562-a6ac-934a38b1e3cd',\n",
       " 136: '0485eacb-defe-40f2-ad6d-395ed53eb938',\n",
       " 137: 'd01ce8ca-a566-4259-9f52-194df47e7ca3',\n",
       " 138: '24a44274-19fb-41a4-b5b8-4ce9312f682b',\n",
       " 139: 'dfc1b159-8cf8-48a6-96d4-89bba7ba3d8d',\n",
       " 140: '837e88c7-3263-4a9f-ae5a-bbae41a840e0',\n",
       " 141: '489ca515-4f5a-4171-92d4-2b342821a68a',\n",
       " 142: 'a24a1a7e-f546-4e5b-b831-5390bee6d63a',\n",
       " 143: 'b1e46a9a-c2f2-410a-82f5-ded3f6363581',\n",
       " 144: '7f0b066c-f07c-4925-ad09-48add1b10f9d',\n",
       " 145: 'ca94fd04-8e93-41e1-bd93-f26b03723c7f',\n",
       " 146: 'dcd82123-c4d0-4eeb-b6cb-b7da9b0f8ed1',\n",
       " 147: '6b1b70a7-2b0a-42e5-bb2e-c3e19da82422',\n",
       " 148: '9620e616-5f06-4dec-858c-b97f01a4199e',\n",
       " 149: 'cf1d00a0-617e-4614-8e0a-ff1703e6eb62',\n",
       " 150: '1b2931ee-ccd0-4aff-96b9-585bf4db43be',\n",
       " 151: 'b70fa2d9-0ab5-4865-9a24-c9bebfbeb5f0',\n",
       " 152: '7dabc517-0717-42cd-8f97-dc5e0a6c7ff1',\n",
       " 153: 'f55fe0d8-f386-493c-ac19-4700a8486264',\n",
       " 154: '2a5d532d-e03e-46a3-accc-a53888b9f40f',\n",
       " 155: '2ad5081e-f7e8-43db-a13e-c0f84255a3e4',\n",
       " 156: '5231cb84-df04-4ef7-84c1-77f3e1139bb3',\n",
       " 157: '8f93bc53-c5ce-4ce3-b51d-5abeec071a1b',\n",
       " 158: '11c4e0e2-4733-4b6e-9d42-f7f677951d11',\n",
       " 159: '28d955e0-62a3-4c52-89ad-3c056352887f',\n",
       " 160: '1181cdee-4ecf-47f9-8861-ff3617df8be9',\n",
       " 161: '93e565e8-8fea-45b5-bccb-1bd8d43989c9',\n",
       " 162: '4dbd8370-8570-49d6-85ae-8bbb14b301c5',\n",
       " 163: 'b8b8f210-d34a-4325-8489-19bd72474f36',\n",
       " 164: '8e502ea6-7607-4e49-8fbb-783a9617e7b5',\n",
       " 165: 'c5774fc3-1068-472a-bbbd-a4049e2f00eb',\n",
       " 166: '79480196-8ed4-461c-986e-342a5e8b3ad3',\n",
       " 167: '0c4bacf3-a806-4cfc-8725-894bb8568433'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387a4b5",
   "metadata": {},
   "source": [
    "Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233ffaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs = {\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9492e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001CB9FFF4050>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d958d580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai we would call it now um people like minsky and and and patrick winston and you know all these characters right and used to debate a few of them and they used to think i was mad thinking about that some new advance could be done with learning systems and um i was actually pleased to hear that because at least you know you're on a unique track at that point right even if every all of your you know professors are telling you you're mad that's true and of course in industry uh you can we couldn't get you know as difficult to get two cents together uh and which is hard to imagine now as well given it's the biggest sort of buzzword in in vcs and and fundraising's easy and all these kind of things today so back in 2010 it was very difficult and what we the reason we started then and shane and i used to discuss um uh uh what were the sort of founding tenets of deep mind and it was very various things one was um algorithmic advances so deep learning you know jeff hinton and cohen just had\n"
     ]
    }
   ],
   "source": [
    "result = retriever.invoke(\"What is deepmind?\")\n",
    "print(result[3].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31fd8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    streaming=False)\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4a61176",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant.\n",
    "    Answer only from the provided transcript context.\n",
    "    If the context is insufficient, just say you don't know.\n",
    "    \n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables = [\"context\",\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d14243b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is the topic of aliens discussed in this video? if yes then what was discussed?\"\n",
    "retrieved_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68b6d50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9e80db38-4b9a-4b7a-9458-369784c3ea7b', metadata={}, page_content=\"space age we should have heard a cacophony of voices we should have joined that cacophony of voices and what we did we opened our ears and we heard nothing and many people who argue that there are aliens would say well we haven't really done exhaustive search yet and maybe we're looking in the wrong bands and and we've got the wrong devices and we wouldn't notice what an alien form was like to be so different to what we're used to but you know i'm not i don't really buy that that it shouldn't be as difficult as that like we i think we've searched enough there should be if it were everywhere if it was it should be everywhere we should see dyson's fears being put up sun's blinking in and out you know there should be a lot of evidence for those things and then there are other people argue well the sort of safari view of like well we're a primitive species still because we're not space faring yet and and and we're you know there's some kind of globe like universal rule not to interfere\"),\n",
       " Document(id='01cef592-f50d-4cf2-9f45-cf83f218b325', metadata={}, page_content=\"thoughts it could be some interactions with our mind that we think are originating from us is actually something that uh is coming from other life forms elsewhere consciousness itself might be that it could be but i don't see any sensible argument to the why why would all of the alien species be using this way yes some of them will be more primitive they would be close to our level you know there would there should be a whole sort of normal distribution of these things right some would be aggressive some would be you know curious others would be very stoical and philosophical because you know maybe they're a million years older than us but it's not it shouldn't be like what i mean one one alien civilization might be like that communicating thoughts and others but i don't see why you know potentially the hundreds there should be would be uniform in this way right it could be a violent dictatorship that the the people the alien civilizations that uh become successful become um [Music]\"),\n",
       " Document(id='81a22867-c83f-40e6-9351-755e25273f8e', metadata={}, page_content=\"potentially the hundreds there should be would be uniform in this way right it could be a violent dictatorship that the the people the alien civilizations that uh become successful become um [Music] gain the ability to be destructive an order of magnitude more destructive but of course the the sad thought well either humans are very special we took a lot of leaps that arrived at what it means to be human yeah um there's a question there which was the hardest which was the most special but also if others have reached this level and maybe many others have reached this level the great filter that prevented them from going farther to becoming a multi-planetary species or reaching out into the stars and those are really important questions for us whether um whether there's other alien civilizations out there or not this is very useful for us to think about if we destroy ourselves how will we do it and how easy is it to do yeah well you know these are big questions and i've thought about\"),\n",
       " Document(id='7788b081-8a3a-42b4-852f-b931082137cd', metadata={}, page_content=\"other option of course we could enhance ourselves and and without devices we we are already sort of symbiotic with our compute devices right with our phones and other things and you know this stuff like neural link and etc that could be could could advance that further um so i think there's lots of lots of really amazing possibilities uh that i could foresee from here well let me ask you some wild questions so out there looking for friends do you think there's a lot of alien civilizations out there so i guess this also goes back to your origin of life question too because i think that that's key um my personal opinion looking at all this and and you know it's one of my hobbies physics i guess so so i i you know it's something i think about a lot and talk to a lot of experts on and and and read a lot of books on and i think my feeling currently is that that we are alone i think that's the most likely scenario given what what evidence we have so um and the reasoning is i think that you\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "714f3ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"space age we should have heard a cacophony of voices we should have joined that cacophony of voices and what we did we opened our ears and we heard nothing and many people who argue that there are aliens would say well we haven't really done exhaustive search yet and maybe we're looking in the wrong bands and and we've got the wrong devices and we wouldn't notice what an alien form was like to be so different to what we're used to but you know i'm not i don't really buy that that it shouldn't be as difficult as that like we i think we've searched enough there should be if it were everywhere if it was it should be everywhere we should see dyson's fears being put up sun's blinking in and out you know there should be a lot of evidence for those things and then there are other people argue well the sort of safari view of like well we're a primitive species still because we're not space faring yet and and and we're you know there's some kind of globe like universal rule not to interfere\\n\\nthoughts it could be some interactions with our mind that we think are originating from us is actually something that uh is coming from other life forms elsewhere consciousness itself might be that it could be but i don't see any sensible argument to the why why would all of the alien species be using this way yes some of them will be more primitive they would be close to our level you know there would there should be a whole sort of normal distribution of these things right some would be aggressive some would be you know curious others would be very stoical and philosophical because you know maybe they're a million years older than us but it's not it shouldn't be like what i mean one one alien civilization might be like that communicating thoughts and others but i don't see why you know potentially the hundreds there should be would be uniform in this way right it could be a violent dictatorship that the the people the alien civilizations that uh become successful become um [Music]\\n\\npotentially the hundreds there should be would be uniform in this way right it could be a violent dictatorship that the the people the alien civilizations that uh become successful become um [Music] gain the ability to be destructive an order of magnitude more destructive but of course the the sad thought well either humans are very special we took a lot of leaps that arrived at what it means to be human yeah um there's a question there which was the hardest which was the most special but also if others have reached this level and maybe many others have reached this level the great filter that prevented them from going farther to becoming a multi-planetary species or reaching out into the stars and those are really important questions for us whether um whether there's other alien civilizations out there or not this is very useful for us to think about if we destroy ourselves how will we do it and how easy is it to do yeah well you know these are big questions and i've thought about\\n\\nother option of course we could enhance ourselves and and without devices we we are already sort of symbiotic with our compute devices right with our phones and other things and you know this stuff like neural link and etc that could be could could advance that further um so i think there's lots of lots of really amazing possibilities uh that i could foresee from here well let me ask you some wild questions so out there looking for friends do you think there's a lot of alien civilizations out there so i guess this also goes back to your origin of life question too because i think that that's key um my personal opinion looking at all this and and you know it's one of my hobbies physics i guess so so i i you know it's something i think about a lot and talk to a lot of experts on and and and read a lot of books on and i think my feeling currently is that that we are alone i think that's the most likely scenario given what what evidence we have so um and the reasoning is i think that you\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "197463b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275be906",
   "metadata": {},
   "source": [
    "Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a995455",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "Client error '401 Unauthorized' for url 'https://router.huggingface.co/v1/chat/completions' (Request ID: Root=1-697a873a-2e1210a30b1357a0566981f6;3b68101d-a11a-4247-8303-02eb23ad9c7a)\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401\n\nInvalid username or password.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\LAPTOP\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:657\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 657\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\LAPTOP\\anaconda3\\Lib\\site-packages\\httpx\\_models.py:829\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    828\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[1;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPStatusError\u001b[0m: Client error '401 Unauthorized' for url 'https://router.huggingface.co/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m answer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minvoke(final_prompt)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\Users\\LAPTOP\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AIMessage:\n\u001b[0;32m    397\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    400\u001b[0m         cast(\n\u001b[0;32m    401\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 402\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    403\u001b[0m                 [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    404\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    405\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    406\u001b[0m                 tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    407\u001b[0m                 metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    408\u001b[0m                 run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    409\u001b[0m                 run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    410\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    411\u001b[0m             )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    412\u001b[0m         )\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[0;32m    413\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LAPTOP\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1119\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1120\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LAPTOP\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    930\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 931\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    932\u001b[0m                 m,\n\u001b[0;32m    933\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    934\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    936\u001b[0m             )\n\u001b[0;32m    937\u001b[0m         )\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    939\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\LAPTOP\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1231\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1233\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1234\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1235\u001b[0m     )\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1237\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LAPTOP\\anaconda3\\Lib\\site-packages\\langchain_huggingface\\chat_models\\huggingface.py:750\u001b[0m, in \u001b[0;36mChatHuggingFace._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    743\u001b[0m     message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    744\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    745\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    746\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    747\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m    748\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    749\u001b[0m     }\n\u001b[1;32m--> 750\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat_completion(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(answer)\n\u001b[0;32m    752\u001b[0m llm_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_chat_prompt(messages)\n",
      "File \u001b[1;32mc:\\Users\\LAPTOP\\anaconda3\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:933\u001b[0m, in \u001b[0;36mInferenceClient.chat_completion\u001b[1;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[0m\n\u001b[0;32m    905\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: payload_model,\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[0;32m    925\u001b[0m }\n\u001b[0;32m    926\u001b[0m request_parameters \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39mprepare_request(\n\u001b[0;32m    927\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m    928\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    931\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[0;32m    932\u001b[0m )\n\u001b[1;32m--> 933\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_post(request_parameters, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LAPTOP\\anaconda3\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:286\u001b[0m, in \u001b[0;36mInferenceClient._inner_post\u001b[1;34m(self, request_parameters, stream)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[0;32m    276\u001b[0m         get_session()\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m         )\n\u001b[0;32m    285\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m     hf_raise_for_status(response)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines()\n",
      "File \u001b[1;32mc:\\Users\\LAPTOP\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:752\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m: Client error '401 Unauthorized' for url 'https://router.huggingface.co/v1/chat/completions' (Request ID: Root=1-697a873a-2e1210a30b1357a0566981f6;3b68101d-a11a-4247-8303-02eb23ad9c7a)\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401\n\nInvalid username or password."
     ]
    }
   ],
   "source": [
    "answer = model.invoke(final_prompt)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932d61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
